"use strict";
/*
 * Wrap the stdout/stderr write function to get a JSON output with request metadata
 * when we are running as a lambda
 */
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
const environment = require('../environment');
const consoleWrapper_1 = __importStar(require("./consoleWrapper"));
const layer0OriginalOutputs = {
    stdoutWrite: process.stdout.write,
    stderrWrite: process.stderr.write,
};
const PINO_ERROR_LEVEL = 50;
const PINO_INFO_LEVEL = 30;
let layer0EnabledCount = 0;
const JSON_LOG_IDENTIFIER = JSON.stringify(consoleWrapper_1.awsCloudWatchTag).replace('{', '').replace('}', '');
/**
 * Check if this log is already wrapped into a json payload
 * @param log
 */
function isLayer0JsonLog(log) {
    return log.indexOf(JSON_LOG_IDENTIFIER) >= 0;
}
// Connascence of values with LeDeployer UI: it depends on the values to correctly
// render the logged request data.
// Connascence of values with Log Streamr lambda: it depends on these values to
// correctly apply the filtering,
const DOWNSTREAM_REQUEST_INFO_LEVEL = 100;
const DOWNSTREAM_RESPONSE_INFO_LEVEL = 101;
const UPSTREAM_REQUEST_INFO_LEVEL = 102;
const UPSTREAM_RESPONSE_INFO_LEVEL = 103;
const UPSTREAM_RESPONSE_BODY_INFO_LEVEL = 104;
// Base JSON object for the ongoing request. In AWS lambda all
// requests are processed serially so we can keep this globally.
// If we have to make this work for local development, we will
// have to use "thread local storage".
let currentBaseJsonObject = {};
function deepRequestInspectionLogger(instance) {
    // Logs the HTTP request information at the given level, provided that
    // the HTTP request logging is globally enabled.
    // This functionn never throws as it is just related to logging and we don't
    // want a request to ever fail due to logging issues.
    function logHttpRequestInfo(data, level) {
        try {
            // A global that is ultimately set through the UI in the environment version.
            if (process.env.LAYER0_HTTP_REQUEST_LOGGING === '1') {
                layer0OriginalOutputs.stdoutWrite.apply(process.stdout, [
                    JSON.stringify({
                        level,
                        time: Date.now(),
                        wi: instance.id,
                        ...currentBaseJsonObject,
                        data,
                    }),
                ]);
                layer0OriginalOutputs.stdoutWrite.apply(process.stdout, ['\n']);
            }
        }
        catch (e) {
            // istanbul ignore next
            console.error(`Error while logging HTTP request info at level ${level}: ${e && e.message}`);
        }
    }
    function logDownstreamRequestInfo(data) {
        return logHttpRequestInfo(data, DOWNSTREAM_REQUEST_INFO_LEVEL);
    }
    function logDownstreamResponseInfo(data) {
        return logHttpRequestInfo(data, DOWNSTREAM_RESPONSE_INFO_LEVEL);
    }
    function logUpstreamRequestInfo(data) {
        return logHttpRequestInfo(data, UPSTREAM_REQUEST_INFO_LEVEL);
    }
    function logUpstreamResponseInfo(data) {
        return logHttpRequestInfo(data, UPSTREAM_RESPONSE_INFO_LEVEL);
    }
    function logUpstreamResponseBodyInfo(data) {
        return logHttpRequestInfo(data, UPSTREAM_RESPONSE_BODY_INFO_LEVEL);
    }
    return {
        logDownstreamRequestInfo,
        logDownstreamResponseInfo,
        logUpstreamRequestInfo,
        logUpstreamResponseInfo,
        logUpstreamResponseBodyInfo,
    };
}
exports.deepRequestInspectionLogger = deepRequestInspectionLogger;
/**
 * Overrides the given stream #write method so that every chunk
 * of text sent to that function is wrapped into a JSON object
 * as a 'msg' attribute.
 * The rest of the JSON object is defined by baseJsonObject
 *
 * @param stream Stream to override
 * @param baseJsonObject JSON object into which we inject the stream message
 */
function jsonifyWriteStream(stream, baseJsonObject) {
    const originalWrite = stream.write;
    // @ts-ignore
    stream.write = function (chunk, ...otherArgs) {
        // Converts Buffer or Uint8Array to string
        let convertedChunk;
        if (typeof chunk === 'object') {
            convertedChunk = Buffer.from(chunk).toString();
        }
        else {
            convertedChunk = chunk;
        }
        const dynamicObject = {
            time: Date.now(),
        };
        // Let JSON pass through without wrapping it again.
        if (chunk && !isLayer0JsonLog(convertedChunk)) {
            chunk =
                JSON.stringify({
                    ...baseJsonObject,
                    ...dynamicObject,
                    msg: convertedChunk,
                }) + '\n';
        }
        // @ts-ignore
        return originalWrite.apply(stream, [chunk, ...otherArgs]);
    };
}
const stdStreamsWrapper = {
    /**
     * Wraps console.xxx methods AND standard streams into a JSON payload that will
     * be sent back to the final user in the log streaming interface.
     *
     * Notes:
     * - We have to wrap standard streams because some logging libraries (like 'consola')
     *   writes to those directly without going through console.xxx
     * - We have to wrap console.xxx methods too, as they don't seem to be bound to
     *   standard streams in AWS Lambda Environment. That wrapper (using pino) streams
     *   to process.stdout, leading to the point below.
     * - Both notes above would result in a double json encapsulation when logging via
     *   console.xxx methods. We prevent that in our standard stream wrapper by detecting
     *   a json string that coming from pino logger.
     */
    enable: ({ clientIp, requestId, wi, } = {}) => {
        if (!environment.isCloud()) {
            return;
        }
        if (layer0EnabledCount === 0) {
            let basePayload = consoleWrapper_1.awsCloudWatchTag;
            if (clientIp) {
                basePayload = {
                    ...basePayload,
                    clientIp,
                };
            }
            if (requestId) {
                basePayload = {
                    ...basePayload,
                    requestId,
                };
            }
            if (wi) {
                basePayload = {
                    ...basePayload,
                    wi,
                };
            }
            // Since lambda processes the requests serially, we can rely on a global.
            currentBaseJsonObject = basePayload;
            // Wrap standard streams as some
            // As we don't have the same degree of "level" details as console methods, we
            // assign INFO for stdout and ERROR for stderr
            jsonifyWriteStream(process.stdout, { level: PINO_INFO_LEVEL, ...basePayload });
            jsonifyWriteStream(process.stderr, { level: PINO_ERROR_LEVEL, ...basePayload });
            // Wrap console.xxx methods
            consoleWrapper_1.default.enable({ clientIp, requestId, wi });
        }
        layer0EnabledCount++;
    },
    disable: () => {
        if (!environment.isCloud()) {
            return;
        }
        layer0EnabledCount--;
        if (layer0EnabledCount === 0) {
            process.stdout.write = layer0OriginalOutputs.stdoutWrite;
            process.stderr.write = layer0OriginalOutputs.stderrWrite;
            currentBaseJsonObject = {};
            consoleWrapper_1.default.disable();
        }
    },
};
exports.default = stdStreamsWrapper;
