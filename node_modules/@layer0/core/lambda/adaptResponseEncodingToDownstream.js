"use strict";
// This module has connascence of behavior with the module of the same name in XBP.
// There are differences in the actual implementation, most notably the use of asynchronous
// compression which relies on the threadpool rather than blocking the main thread.
// In lambda we are free to block the main thread as lambda processes the requests serially.
// In XBP we are not free to block the main thread as it processes many requests concurrently.
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const zlib_1 = require("zlib");
const constants_1 = require("../constants");
const content_type_1 = require("content-type");
const isEmpty_1 = __importDefault(require("../utils/isEmpty"));
const isString_1 = __importDefault(require("../utils/isString"));
const decode_1 = __importDefault(require("../utils/decode"));
/**
 * Those content types that will be gzipped are generated from the lists in:
 * our Layer0 v1 production Nginx + Layer0 v1 production Varnish + default CDN gzip policy
 *
 * Set is not always optimal but in the benchmarks came out on top the most times.
 * It is also the easiest to read and check for correctness.
 */
const COMPRESSIBLE_TYPES = new Set([
    'application/atom_xml',
    'application/javascript',
    'application/json',
    'application/rss+xml',
    'application/vnd.ms-fontobject',
    'application/x-font-opentype',
    'application/x-font-ttf',
    'application/x-javascript',
    'application/xhtml+xml',
    'application/xml',
    'application/xml+rss',
    'font/eot',
    'font/opentype',
    'font/otf',
    'image/svg+xml',
    'image/x-icon',
    'text/css',
    'text/html',
    'text/javascript',
    'text/js',
    'text/plain',
]);
/**
 * Adapts the response body to the downstream accept encoding. This may mean:
 * a) Not doing anything if the downstream accept encoding the content encoding are compatible.
 * b) Compressing the response body to a downstream compatible encoding, if response body has no encoding.
 * c) Decompressing the response body from downstream incompatible encoding and optionally re-compressing it
 * to downstream compatible encoding.
 *
 * If any compression is done by this function, then the content-encoding and content-length headers will
 * correspond to the new encoding/length of the response body.
 *
 * @param acceptEncoding Value of downstream accept-encoding header
 * @param res HttpResponse object
 * @param response Lambda response object
 */
const adaptResponseEncodingToDownstream = (acceptEncoding, res, response) => {
    let contentEncoding = res.getHeader(constants_1.HTTP_HEADERS.contentEncoding);
    // Figure out if we first need to encode anything.
    if (isEmpty_1.default(acceptEncoding)) {
        if (!isEmpty_1.default(contentEncoding)) {
            // Best effort to decode and return the decoded body.
            decode_1.default(res);
            response.body = res.body;
        }
        return;
    }
    const BROTLI_ENCODING_REGEX = /\bbr\b/;
    const GZIP_ENCODING_REGEX = /\bgzip\b/;
    const downstreamIsGzipCompatible = GZIP_ENCODING_REGEX.test(acceptEncoding);
    const downstreamIsBrotliCompatible = BROTLI_ENCODING_REGEX.test(acceptEncoding);
    if (downstreamIsGzipCompatible && contentEncoding === constants_1.GZIP_ENCODING) {
        return;
    }
    if (downstreamIsBrotliCompatible && contentEncoding === constants_1.BROTLI_ENCODING) {
        return;
    }
    // Try to decode the content. If we cannot decode then we will pass the content
    // as-is and on the edge we will refuse to cache it (see the logic in upstream
    // response handling on the edge and specifically the bad-encoding caching status)
    if (!decode_1.default(res)) {
        return;
    }
    // Since AWS lambda holds multiValueHeaders as array convert string to array
    let contentType = res.getHeader(constants_1.HTTP_HEADERS.contentType);
    contentType = isString_1.default(contentType) ? [contentType] : contentType;
    // Return body if content-type does not exist or match the list of mimes
    if (!contentType ||
        !COMPRESSIBLE_TYPES.has(content_type_1.parse(contentType[0]).type.toLowerCase())) {
        return;
    }
    // If request accepts a gzip response, then encode it with gzip.
    // If request accepts a brotli response, then encoding it with brotli.
    // If both are acceptable then use gzip which we prefer gzip compression in lambda because
    // while the lambdas can scale (unlike the edge) the throughout for small un-cached objects
    // has been observed to drop by 40%.
    // End developers can work around this default behavior by doing the Brotli compression
    // themselves and correctly setting the `content-encoding`.
    let targetContentEncoding;
    if (downstreamIsGzipCompatible) {
        targetContentEncoding = constants_1.GZIP_ENCODING;
    }
    else if (downstreamIsBrotliCompatible) {
        targetContentEncoding = constants_1.BROTLI_ENCODING;
    }
    // Encode the body.
    let encodedBody;
    switch (targetContentEncoding) {
        case constants_1.BROTLI_ENCODING: {
            encodedBody = zlib_1.brotliCompressSync(Buffer.from(response.body));
            break;
        }
        case constants_1.GZIP_ENCODING: {
            encodedBody = zlib_1.gzipSync(Buffer.from(response.body));
            break;
        }
        default: {
            // We only support gzip and brotli so if neither is supported we just return
            // the un-encoded response.
            return;
        }
    }
    // Set the response headers and body.
    res.setHeader(constants_1.HTTP_HEADERS.contentLength, Buffer.byteLength(encodedBody));
    res.setHeader(constants_1.HTTP_HEADERS.contentEncoding, targetContentEncoding);
    response.body = encodedBody;
};
exports.default = adaptResponseEncodingToDownstream;
