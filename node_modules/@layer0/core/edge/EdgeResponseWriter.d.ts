import { CacheOptions } from '../router/CacheOptions';
import { EdgeRule, EdgeRoute } from '../types';
import { ProxyOptions, RedirectOptions, ServeStaticOptions, VerifyJwtOptions } from '../router/ResponseWriter';
import ResponseWriter from '../router/ResponseWriter';
import Route from '../router/Route';
import RequestContext from '../router/RequestContext';
import Request from '../router/Request';
import Response from '../router/Response';
/**
 * A substitute implementation of `ResponseWriter` that creates the contents of `layer0.json`, which
 * is used to generate edge code.
 */
export default class EdgeResponseWriter extends ResponseWriter {
    readonly edgeConfig: EdgeRule;
    stream: () => void;
    /**
     * @param req The `HttpRequest` object
     * @param res The `HttpResponse` object
     * @param route The route being hit
     * @param context The request context
     */
    constructor(_req: any, _res: any, route: Route, context: RequestContext);
    setRequestHeader: (name: string, value: string) => void;
    updateRequestHeader: (name: string, match: RegExp, replace: string) => void;
    removeRequestHeader: (name: string) => void;
    setResponseHeader: (name: string, value: string) => void;
    updateResponseHeader: (name: string, match: RegExp, replace: string) => void;
    removeResponseHeader: (name: string) => void;
    /**
     * Note:
     * * We allow x-0-surrogate-key upstream response headers to be set by the edge logic,
     * to equalizes what can be done in the serverless vs what can be done in the edge.
     * * We do not extend this to other response headers because there are many that are
     * set internally in VCL (e.g. x-0-version, x-0-shield-response, x-0-isg-loading-page-served,
     * x-0-caching-status, and so on) which if affected would interfere with the correct
     * functioning of the service.
     */
    setUpstreamResponseHeader: (name: string, value: string) => void;
    updateUpstreamResponseHeader: (name: string, match: RegExp, replace: string) => void;
    removeUpstreamResponseHeader: (name: string) => void;
    addResponseCookie: (name: string, value: string) => void;
    updateResponseCookie: (name: string, match: RegExp, replace: string) => void;
    removeResponseCookie: (name: string) => void;
    addUpstreamResponseCookie: (name: string, value: string) => void;
    updateUpstreamResponseCookie: (name: string, match: RegExp, replace: string) => void;
    removeUpstreamResponseCookie: (name: string) => void;
    private shouldParseQueryString;
    /**
     * Sends a redirect from the edge
     *
     * In case of a complex redirect where the router needs to parse query string
     * from the matched request, or inject query strings in the redirect, we delegate
     * the response to Serverless compute and cache it for a very long time.
     *
     *
     * @param to The destination URL
     * @param statusCode The http response status.
     */
    redirect: (to: string, options?: RedirectOptions) => void;
    /**
     * Serves static assets.
     * @param path The request path
     */
    serveStatic: (path: string, { permanent, exclude, onNotFound, loadingPage, expiresSeconds, statusCode, statusMessage, disableAutoPublish, }?: ServeStaticOptions) => Promise<void>;
    verifyJwt: (options: VerifyJwtOptions) => Promise<void>;
    /**
     * Proxies from the edge
     * @param backend
     * @param config
     * @param config.path
     */
    proxy: (backend: string, { path, transformResponse, transformRequest }?: ProxyOptions) => Promise<void>;
    /**
     * Rewrites the request path.
     */
    updatePath: (destination: string) => void;
    /**
     * Sets the edge route and injects the x-0-route header value.
     *
     * Notes:
     * - We need `x-0-route` header for statistics so we log it in the edge.
     * We thus set it on the request, which allows us to log it, but in the edge
     * code we unset this header before going upstream which avoids any leaking.
     * - route.criteria.path can be null (fallback, or different match method)
     * so we check that the path exists or injecting the request path as a fallback.
     * - We don't allow upstream to dicate the `vary` header - developers can use
     * our custom cache key mechanism which is a superset anyways. The only
     * header we allow in the `vary` is `accept-encoding` which then shards
     * the cache depending on the encoding that the user agent is accepting.
     * In any case we already include `accept-encoding` in the default cache
     * key so including it in `vary` is superfluous *except* that downstream
     * caches might use it.
     *
     * @private
     */
    setEdgeRoute(route: EdgeRoute): void;
    /**
     * Creates the edge cache config
     * @param config
     */
    cache: (config: CacheOptions) => void;
    /**
     * Sends string content back to client. If content is a string, the response will be sent
     * directly from the edge. If it is a function, the request will be computed by a JavaScript worker.
     * StatusCode defaults to 200 on routes which is set by createEdgeConfig. On error routes we send the status code
     * as null, since we need to preserve the status code of the failed request unless it is provided.
     * @param content The content to send to the browser
     * @param statusCode The HTTP status code.
     * @param statusMessage The HTTP status message
     */
    send: (content: string | (() => string), statusCode: number | undefined, statusMessage?: string | undefined) => void;
    /**
     * Computed responses are always proxied to the serverless backend.
     * @param callback
     */
    compute: (callback: (request: Request, response: Response) => void | Promise<void>) => void;
    /**
     * Passes request and response to the specified callback, which should
     * handle rendering the response as a string
     */
    render: () => Promise<void>;
}
