"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const PrefetchPlugin_1 = require("./PrefetchPlugin");
/**
 * Time after which we clear a given request metadata from memory.
 * This must be above usual http timeouts to be sure the request is completed.
 */
const CURRENT_REQUEST_MAP_CLEANUP_DELAY = 120000;
class DevtoolsPlugin {
    constructor({ onResponse, routeConfig, isEnabledFn, }) {
        this.currentRequests = {};
        this.onResponse = onResponse;
        this.routeConfig = routeConfig;
        this.isEnabledFn = isEnabledFn;
    }
    /**
     * Stores information about a request to be used by subsequent plugin steps
     *
     * IMPORTANT We do **not** use a custom header to store the metadata: a custom header leads
     * to CORS pre-flight requests when using cache on a different origin, and those would likely
     * reject our header.
     * (more info https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#Preflighted_requests)
     *
     * Unfortunately, there does not seem to be another way to (or if there is, feel free to fix this):
     * - store information on the request instance that we be passed along to subsequent steps
     * - identify a request uniquely with some sort of internal id
     *
     * For now, the solution is to use the normalized cache key to identify each request "uniquely",
     * although that would lead to inconsistent results if a same request happens multiple time concurrently.
     * It also adds overhead, especially for POST graphql query which serializes the body.
     *
     * After CURRENT_REQUEST_MAP_CLEANUP_DELAY, the metadata is cleared to avoid a memory leak.
     * We don't clear explicitly from cachedResponseWillBeUsed/fetchDidSucceed, as it very complex (impossible?) to do it right:
     * - we would need a counter on the current requests to be sure to not clear the metadata from concurrent equivalent request
     * - incrementing/decrementing because we don't know in advance through which
     *   plugin functions the request will go through, which is the first and which
     *   is the last. We could make assumptions but that would lead to fragility.
     */
    async saveRequestMetadata(request, metadata) {
        var _a, _b;
        const normalizedUrl = await PrefetchPlugin_1.normalizeRequestUrlForCache(request);
        if ((_a = this.currentRequests[normalizedUrl]) === null || _a === void 0 ? void 0 : _a.cleanupTimeout) {
            clearTimeout(this.currentRequests[normalizedUrl].cleanupTimeout);
        }
        this.currentRequests[normalizedUrl] = {
            metadata: {
                ...(_b = this.currentRequests[normalizedUrl]) === null || _b === void 0 ? void 0 : _b.metadata,
                ...metadata,
            },
            cleanupTimeout: setTimeout(() => {
                delete this.currentRequests[normalizedUrl];
            }, CURRENT_REQUEST_MAP_CLEANUP_DELAY),
        };
    }
    async getRequestMetadata(request) {
        var _a;
        const normalizedUrl = await PrefetchPlugin_1.normalizeRequestUrlForCache(request);
        return ((_a = this.currentRequests[normalizedUrl]) === null || _a === void 0 ? void 0 : _a.metadata) || {};
    }
    /**
     * Notes:
     * - It seems that we cannot add arbitrary attributes to the request object
     *   so the best we can do is to store request info in a memory hash-map
     */
    async requestWillFetch({ request }) {
        if (!this.isEnabledFn()) {
            return request;
        }
        await this.saveRequestMetadata(request, { requestStart: Date.now() });
        return request;
    }
    /**
     * Called when an object is read from or written to the cache.
     *
     * Notes:
     * - It seems that we cannot add arbitrary attributes to the request object
     *   so the best we can do is to store request info in a memory hash-map
     *
     * - In case of cache 'read', we keep track of prefetch request so that we can identify them later
     *   in `cachedResponseWillBeUsed`, which is called for both hit or miss.
     *   Why here and not on response? Because in `cachedResponseWillBeUsed` we only get the cache-normalized request
     *   where layer0_dt_pf query string got removed
     */
    async cacheKeyWillBeUsed({ request, mode }) {
        if (!this.isEnabledFn()) {
            return request;
        }
        if (mode === 'read') {
            await this.saveRequestMetadata(request, {
                isPrefetch: PrefetchPlugin_1.isPrefetchRequest(request),
            });
        }
        return request;
    }
    async cachedResponseWillBeUsed({ request, cachedResponse: response, }) {
        if (!this.isEnabledFn()) {
            return response;
        }
        // In case of cache miss
        if (!response)
            return response;
        const { isPrefetch } = await this.getRequestMetadata(request);
        // TTFB is hard-coded to 0 for cached response
        this.onResponse({
            browserCache: 'hit',
            ttfb: 0,
            prefetch: isPrefetch,
            request,
            response,
            routeConfig: this.routeConfig,
        });
        return response;
    }
    async fetchDidSucceed({ request, response }) {
        if (!this.isEnabledFn()) {
            return response;
        }
        const { requestStart } = await this.getRequestMetadata(request);
        const ttfb = requestStart && Date.now() - requestStart;
        this.onResponse({
            browserCache: 'miss',
            ttfb,
            prefetch: PrefetchPlugin_1.isPrefetchRequest(request),
            request,
            response,
            routeConfig: this.routeConfig,
        });
        return response;
    }
}
exports.default = DevtoolsPlugin;
